Initializing training
Starting training
Epoch 0
Train Batch 0/11797: Loss: 7.909874439239502
Train Batch 1/11797: Loss: 7.6699018478393555
Train Batch 2/11797: Loss: 6.37332820892334
Train Batch 3/11797: Loss: 5.8100056648254395
Train Batch 4/11797: Loss: 6.327473163604736
Train Batch 5/11797: Loss: 3.941105365753174
Train Batch 6/11797: Loss: 4.046220302581787
Train Batch 7/11797: Loss: 3.6046693325042725
Train Batch 8/11797: Loss: 3.0519461631774902
Train Batch 9/11797: Loss: 3.499865770339966
Train Batch 10/11797: Loss: 3.4152419567108154
Train Batch 11/11797: Loss: 3.8817648887634277
Train Batch 12/11797: Loss: 2.9985334873199463
Train Batch 13/11797: Loss: 2.017120122909546
Train Batch 14/11797: Loss: 3.4088897705078125
Train Batch 15/11797: Loss: 2.417935609817505
Train Batch 16/11797: Loss: 3.1988775730133057
Train Batch 17/11797: Loss: 2.2669076919555664
Train Batch 18/11797: Loss: 2.486686944961548
Train Batch 19/11797: Loss: 2.820526599884033
Train Batch 20/11797: Loss: 1.9046900272369385
Train Batch 21/11797: Loss: 1.6742666959762573
Train Batch 22/11797: Loss: 1.927748203277588
Train Batch 23/11797: Loss: 2.002627372741699
Train Batch 24/11797: Loss: 3.0864973068237305
Train Batch 25/11797: Loss: 1.7124106884002686
Train Batch 26/11797: Loss: 1.4861598014831543
Train Batch 27/11797: Loss: 1.845455527305603
Train Batch 28/11797: Loss: 1.969427466392517
Train Batch 29/11797: Loss: 1.929878830909729
Train Batch 30/11797: Loss: 2.67615008354187
Train Batch 31/11797: Loss: 1.503907322883606
Train Batch 32/11797: Loss: 1.3971667289733887
Train Batch 33/11797: Loss: 1.7845897674560547
Train Batch 34/11797: Loss: 1.7530468702316284
Train Batch 35/11797: Loss: 1.786923885345459
Train Batch 36/11797: Loss: 1.8479423522949219
Train Batch 37/11797: Loss: 1.7177869081497192
Train Batch 38/11797: Loss: 1.5362718105316162
Train Batch 39/11797: Loss: 3.126025438308716
Train Batch 40/11797: Loss: 1.685736894607544
Train Batch 41/11797: Loss: 2.079841136932373
Train Batch 42/11797: Loss: 1.7142212390899658
Train Batch 43/11797: Loss: 1.3318614959716797
Train Batch 44/11797: Loss: 1.3371769189834595
Train Batch 45/11797: Loss: 1.8723129034042358
Train Batch 46/11797: Loss: 1.938337802886963
Train Batch 47/11797: Loss: 1.513208270072937
Train Batch 48/11797: Loss: 1.9166197776794434
Train Batch 49/11797: Loss: 1.6678708791732788
Train Batch 50/11797: Loss: 1.1119110584259033
Train Batch 51/11797: Loss: 2.0228726863861084
Train Batch 52/11797: Loss: 2.0441181659698486
Train Batch 53/11797: Loss: 2.282857656478882
Train Batch 54/11797: Loss: 1.5395549535751343
Train Batch 55/11797: Loss: 2.3852944374084473
Train Batch 56/11797: Loss: 1.8007797002792358
Train Batch 57/11797: Loss: 1.0586267709732056
Train Batch 58/11797: Loss: 1.9462307691574097
Train Batch 59/11797: Loss: 1.840515375137329
Train Batch 60/11797: Loss: 1.495628833770752
Train Batch 61/11797: Loss: 1.5689345598220825
Train Batch 62/11797: Loss: 1.9136162996292114
Train Batch 63/11797: Loss: 1.4656121730804443
Train Batch 64/11797: Loss: 1.4898977279663086
Train Batch 65/11797: Loss: 1.1766759157180786
Train Batch 66/11797: Loss: 1.9284275770187378
Train Batch 67/11797: Loss: 2.2702579498291016
Train Batch 68/11797: Loss: 1.2087948322296143
Train Batch 69/11797: Loss: 1.476845383644104
Train Batch 70/11797: Loss: 1.7234725952148438
Train Batch 71/11797: Loss: 1.0465067625045776
Train Batch 72/11797: Loss: 1.182637333869934
Train Batch 73/11797: Loss: 1.036198616027832
Train Batch 74/11797: Loss: 0.8198374509811401
Train Batch 75/11797: Loss: 1.0567103624343872
Train Batch 76/11797: Loss: 1.3289284706115723
Train Batch 77/11797: Loss: 0.9612708687782288
Train Batch 78/11797: Loss: 2.1592702865600586
Train Batch 79/11797: Loss: 1.9589896202087402
Train Batch 80/11797: Loss: 1.2024281024932861
Train Batch 81/11797: Loss: 1.5797709226608276
Train Batch 82/11797: Loss: 1.5017932653427124
Train Batch 83/11797: Loss: 1.2229032516479492
Train Batch 84/11797: Loss: 1.735039472579956
Train Batch 85/11797: Loss: 1.3677241802215576
Train Batch 86/11797: Loss: 1.1239193677902222
Train Batch 87/11797: Loss: 2.370966672897339
Train Batch 88/11797: Loss: 1.2083561420440674
Train Batch 89/11797: Loss: 0.8176279067993164
Train Batch 90/11797: Loss: 1.1280103921890259
Train Batch 91/11797: Loss: 1.23307204246521
Train Batch 92/11797: Loss: 1.9856979846954346
Train Batch 93/11797: Loss: 0.9214564561843872
Train Batch 94/11797: Loss: 0.7734711766242981
Train Batch 95/11797: Loss: 1.9599052667617798
Train Batch 96/11797: Loss: 1.5713609457015991
Train Batch 97/11797: Loss: 2.1418285369873047
Train Batch 98/11797: Loss: 1.14304780960083
Train Batch 99/11797: Loss: 2.303083658218384
Train Batch 100/11797: Loss: 1.4693018198013306
Train Batch 101/11797: Loss: 0.9330388307571411
Train Batch 102/11797: Loss: 1.8142985105514526
Train Batch 103/11797: Loss: 0.7941566705703735
Train Batch 104/11797: Loss: 1.5335842370986938
Train Batch 105/11797: Loss: 1.6095184087753296
Train Batch 106/11797: Loss: 0.9549327492713928
Train Batch 107/11797: Loss: 1.377458930015564
Train Batch 108/11797: Loss: 1.3492258787155151
Train Batch 109/11797: Loss: 1.0301700830459595
Train Batch 110/11797: Loss: 1.992156744003296
Train Batch 111/11797: Loss: 1.3115404844284058
